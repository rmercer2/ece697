{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## This file builds the dissimilarity matrices from one week of data\n",
    "## Required files: 'locations.csv' and '2021_04_01_week_associations_times.csv'\n",
    "## Produces files:\n",
    "##                - 'ds_mat_b_avg.csv'\n",
    "##                - 'ds_mat_b_min.csv'\n",
    "##                - 'ds_mat_b_avg_scaled.csv'\n",
    "##                - 'ds_mat_b_min_scaled.csv'\n",
    "##                - 'ds_mat_ap_avg.csv'\n",
    "##                - 'ds_mat_ap_min.csv'\n",
    "##                - 'ds_mat_ap_avg_scaled.csv'\n",
    "##                - 'ds_mat_ap_min_scaled.csv'\n",
    "## NOTE: USE ONLY SUBSET FOR ACCESS POINT TO ACCESS POINT MATRIX\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ap_1</th>\n",
       "      <th>ap_2</th>\n",
       "      <th>total_time</th>\n",
       "      <th>frequency</th>\n",
       "      <th>min_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1106</td>\n",
       "      <td>412028</td>\n",
       "      <td>1150.462876</td>\n",
       "      <td>1</td>\n",
       "      <td>1150.462876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>412046</td>\n",
       "      <td>8666.911970</td>\n",
       "      <td>2</td>\n",
       "      <td>4332.140609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106</td>\n",
       "      <td>412126</td>\n",
       "      <td>15732.078110</td>\n",
       "      <td>4</td>\n",
       "      <td>3565.275391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1106</td>\n",
       "      <td>412130</td>\n",
       "      <td>22974.635946</td>\n",
       "      <td>6</td>\n",
       "      <td>3524.078823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1106</td>\n",
       "      <td>412135</td>\n",
       "      <td>1147.993553</td>\n",
       "      <td>1</td>\n",
       "      <td>1147.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528277</th>\n",
       "      <td>424298</td>\n",
       "      <td>424291</td>\n",
       "      <td>36051.810511</td>\n",
       "      <td>9</td>\n",
       "      <td>3015.520140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528278</th>\n",
       "      <td>424298</td>\n",
       "      <td>424293</td>\n",
       "      <td>2147.377507</td>\n",
       "      <td>6</td>\n",
       "      <td>31.433817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528279</th>\n",
       "      <td>424298</td>\n",
       "      <td>424295</td>\n",
       "      <td>29788.171607</td>\n",
       "      <td>12</td>\n",
       "      <td>254.751505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528280</th>\n",
       "      <td>424298</td>\n",
       "      <td>424296</td>\n",
       "      <td>11942.503216</td>\n",
       "      <td>3</td>\n",
       "      <td>3600.144133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528281</th>\n",
       "      <td>424298</td>\n",
       "      <td>424297</td>\n",
       "      <td>21825.901623</td>\n",
       "      <td>15</td>\n",
       "      <td>103.764415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16528282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ap_1    ap_2    total_time  frequency     min_time\n",
       "0           1106  412028   1150.462876          1  1150.462876\n",
       "1           1106  412046   8666.911970          2  4332.140609\n",
       "2           1106  412126  15732.078110          4  3565.275391\n",
       "3           1106  412130  22974.635946          6  3524.078823\n",
       "4           1106  412135   1147.993553          1  1147.993553\n",
       "...          ...     ...           ...        ...          ...\n",
       "16528277  424298  424291  36051.810511          9  3015.520140\n",
       "16528278  424298  424293   2147.377507          6    31.433817\n",
       "16528279  424298  424295  29788.171607         12   254.751505\n",
       "16528280  424298  424296  11942.503216          3  3600.144133\n",
       "16528281  424298  424297  21825.901623         15   103.764415\n",
       "\n",
       "[16528282 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import associations data generated from DataPreprocessing_2021_04_01_week notebook\n",
    "# schema: ap_1, ap_2, total_time, frequency, min_time\n",
    "week_associations_times_df = pd.read_csv('2021_04_01_week_associations_times.csv')\n",
    "week_associations_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>installation_id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419351</td>\n",
       "      <td>1220cc-122-1</td>\n",
       "      <td>43.069064</td>\n",
       "      <td>-89.406687</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418533</td>\n",
       "      <td>1220cc-125-1</td>\n",
       "      <td>43.068890</td>\n",
       "      <td>-89.406787</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419142</td>\n",
       "      <td>1220cc-140-1</td>\n",
       "      <td>43.068924</td>\n",
       "      <td>-89.406417</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418868</td>\n",
       "      <td>1220cc-144-1</td>\n",
       "      <td>43.069336</td>\n",
       "      <td>-89.406421</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419098</td>\n",
       "      <td>1220cc-165-1</td>\n",
       "      <td>43.069081</td>\n",
       "      <td>-89.406393</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>415857</td>\n",
       "      <td>zoo-443-1</td>\n",
       "      <td>43.071706</td>\n",
       "      <td>-89.405150</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>416868</td>\n",
       "      <td>zoo-449-1</td>\n",
       "      <td>43.071860</td>\n",
       "      <td>-89.405114</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>415838</td>\n",
       "      <td>zoo-455-1</td>\n",
       "      <td>43.071739</td>\n",
       "      <td>-89.405175</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>415915</td>\n",
       "      <td>zoo-461-1</td>\n",
       "      <td>43.072012</td>\n",
       "      <td>-89.405152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>416300</td>\n",
       "      <td>zoo-5-1</td>\n",
       "      <td>43.071954</td>\n",
       "      <td>-89.405252</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10997 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       installation_id          name   latitude  longitude  accuracy\n",
       "0               419351  1220cc-122-1  43.069064 -89.406687        20\n",
       "1               418533  1220cc-125-1  43.068890 -89.406787        20\n",
       "2               419142  1220cc-140-1  43.068924 -89.406417        20\n",
       "3               418868  1220cc-144-1  43.069336 -89.406421        34\n",
       "4               419098  1220cc-165-1  43.069081 -89.406393        20\n",
       "...                ...           ...        ...        ...       ...\n",
       "10992           415857     zoo-443-1  43.071706 -89.405150        30\n",
       "10993           416868     zoo-449-1  43.071860 -89.405114        30\n",
       "10994           415838     zoo-455-1  43.071739 -89.405175        20\n",
       "10995           415915     zoo-461-1  43.072012 -89.405152        30\n",
       "10996           416300       zoo-5-1  43.071954 -89.405252        20\n",
       "\n",
       "[10997 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import locations information\n",
    "# schema: installation_id, name, latitude, longitude, accuracy\n",
    "locations_df = pd.read_csv('locations.csv')\n",
    "locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of installation_id (key) to building name (value)\n",
    "id_name = {}\n",
    "# list of all the buildings\n",
    "building_names = [] \n",
    "\n",
    "prev_name = None\n",
    "for i, row in locations_df.iterrows():\n",
    "    # get current name and current installation id\n",
    "    curr_name = row['name'].split('-')[0]\n",
    "    curr_id = row['installation_id']\n",
    "    \n",
    "    # get unique building names\n",
    "    if prev_name == None:\n",
    "        prev_name = curr_name\n",
    "    elif prev_name != curr_name:\n",
    "        building_names.append(prev_name)\n",
    "        prev_name = curr_name\n",
    "    \n",
    "    # access point --> buildings (that the access point is in)\n",
    "    if curr_id not in id_name:\n",
    "        id_name[curr_id] = curr_name\n",
    "        \n",
    "building_names.append(curr_name)\n",
    "\n",
    "# store number of buildings\n",
    "n_buildings = len(building_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDINGS\n",
    "# buildings DS matrices will be n_buildings x n_buildings\n",
    "# where n_buildings is the number of buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mappings to make look ups when buidling Buildings ds matrices faster\n",
    "\n",
    "# map of building name (key) to index (between 0 and number of unique buildings) (value)\n",
    "name_index = {}\n",
    "# map of index (key) to building name (value)\n",
    "index_name = {}\n",
    "\n",
    "for i in range(n_buildings):\n",
    "    name_index[building_names[i]] = i\n",
    "    index_name[i] = building_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track total frequency\n",
    "buildings_N = 0\n",
    "\n",
    "# track building frequency\n",
    "buildings_df = np.zeros((n_buildings,))\n",
    "\n",
    "# track association frequency\n",
    "buildings_tf = np.zeros((n_buildings,n_buildings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,    0.        , 2982.77303707, ..., 5952.310018  ,\n",
       "        3282.16101761,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [2982.77303707,    0.        ,    0.        , ..., 2794.30090753,\n",
       "        1544.27690839,    0.        ],\n",
       "       ...,\n",
       "       [5952.310018  ,    0.        , 2794.30090753, ...,    0.        ,\n",
       "        3368.10203384,    0.        ],\n",
       "       [3282.16101761,    0.        , 1544.27690839, ..., 3368.10203384,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix B_avg: \n",
    "# Pairwise distance of buildings using average time apart and no scaling\n",
    "################################################################################\n",
    "\n",
    "ds_mat_b_sum = np.zeros((n_buildings,n_buildings))\n",
    "ds_mat_b_freq = np.zeros((n_buildings,n_buildings))\n",
    "#ds_mat_b_avg = np.zeros((n_buildings,n_buildings))\n",
    "\n",
    "# fill ds matrix\n",
    "for i, row in week_associations_times_df.iterrows():\n",
    "    if row['ap_1'] in id_name and row['ap_2'] in id_name: # handles any errors in the ids\n",
    "        name1 = id_name[row['ap_1']]\n",
    "        name2 = id_name[row['ap_2']]\n",
    "        if name1 != name2:\n",
    "            index1 = name_index[name1]\n",
    "            index2 = name_index[name2]\n",
    "            \n",
    "            # update ds mat sum and frequency\n",
    "            ds_mat_b_sum[index1][index2] += row['total_time']\n",
    "            ds_mat_b_sum[index2][index1] += row['total_time']\n",
    "            ds_mat_b_freq[index1][index2] += row['frequency']\n",
    "            ds_mat_b_freq[index2][index1] += row['frequency']\n",
    "\n",
    "\n",
    "# calculate avg for ds mat\n",
    "ds_mat_b_avg = np.divide(ds_mat_b_sum, ds_mat_b_freq)\n",
    "\n",
    "# catch and fix overflow errors\n",
    "ds_mat_b_avg[np.isnan(ds_mat_b_avg)] = 0\n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_b_avg.csv', ds_mat_b_avg, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix B_min: \n",
    "# Pairwise distance of buildings using minimum time apart and no scaling\n",
    "################################################################################\n",
    "ds_mat_b_min = np.zeros((n_buildings,n_buildings))\n",
    "\n",
    "# fill ds matrix\n",
    "for i, row in week_associations_times_df.iterrows():\n",
    "    if row['ap_1'] in id_name and row['ap_2'] in id_name: # handles any errors in the ids\n",
    "        name1 = id_name[row['ap_1']]\n",
    "        name2 = id_name[row['ap_2']]\n",
    "        if name1 != name2:\n",
    "            index1 = name_index[name1]\n",
    "            index2 = name_index[name2]\n",
    "            \n",
    "            if (ds_mat_b_min[index1][index2] == 0) or (row['min_time'] < ds_mat_b_min[index1][index2]):\n",
    "                ds_mat_b_min[index1][index2] = row['min_time']\n",
    "                ds_mat_b_min[index2][index1] = row['min_time']\n",
    "                \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_b_min.csv', ds_mat_b_min, delimiter=',', fmt='%d')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# calculate how to scale the values\n",
    "####################################\n",
    "\n",
    "# building frequency scaling\n",
    "# scaling by a version of tfidf\n",
    "# tf = term frequency (number of times the connection between building a, b appears)\n",
    "# idf = inverse document frequency = log(N/df)\n",
    "# N = total number of connections between all buildings\n",
    "# df = document frequency (sum of freq of union of connections that building a and building b each have)\n",
    "\n",
    "# track total frequency\n",
    "buildings_N = sum(sum(ds_mat_b_freq))\n",
    "\n",
    "# track building frequency\n",
    "buildings_df = ds_mat_b_freq.sum(axis=0)\n",
    "\n",
    "# track association frequency\n",
    "# ds_mat_b_freq is tf\n",
    "\n",
    "buildings_tfidf = np.zeros((n_buildings,n_buildings))\n",
    "\n",
    "# calculate tfidf\n",
    "for i in range(n_buildings):\n",
    "    for j in range(i+1,n_buildings):\n",
    "        if (i != j) and (ds_mat_b_avg[i][j] != 0) and ((buildings_df[i] + buildings_df[j] - ds_mat_b_freq[i][j]) != 0):\n",
    "            buildings_tfidf[i][j] = ds_mat_b_freq[i][j] * np.log(buildings_N/(buildings_df[i] + buildings_df[j] - ds_mat_b_freq[i][j]))\n",
    "\n",
    "# catch divide by zero problems\n",
    "buildings_tfidf[buildings_tfidf == inf] = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix B_avg_scaled: \n",
    "# Pairwise distance of buildings using average time apart with frequency scaling\n",
    "################################################################################\n",
    "ds_mat_b_avg_scaled = np.zeros((n_buildings,n_buildings))\n",
    "for i in range(n_buildings):\n",
    "    for j in range(i+1,n_buildings):\n",
    "        if (i != j):\n",
    "            ds_mat_b_avg_scaled[i][j] = ds_mat_b_avg_scaled[j][i] = buildings_tfidf[i][j] * ds_mat_b_avg[i][j]\n",
    "            \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_b_avg_scaled.csv', ds_mat_b_avg_scaled, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix B_min_scaled: \n",
    "# Pairwise distance of buildings using minimum time apart with frequency scaling\n",
    "################################################################################\n",
    "ds_mat_b_min_scaled = np.zeros((n_buildings,n_buildings))\n",
    "for i in range(n_buildings):\n",
    "    for j in range(i+1,n_buildings):\n",
    "        if (i != j):\n",
    "            ds_mat_b_min_scaled[i][j] = ds_mat_b_min_scaled[j][i] = buildings_tfidf[i][j] * ds_mat_b_min[i][j]\n",
    "            \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_b_min_scaled.csv', ds_mat_b_min_scaled, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# save labels for ds building mat\n",
    "####################################\n",
    "np.savetxt(\"ds_mat_labels_b.csv\", building_names, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# get subset\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,   0, 161, 158,   0, 157, 154, 101, 143, 162, 157, 160,   0,\n",
       "       150, 106,   0, 153, 110,  85,   0,   0,   0,   0, 159,   0, 159,\n",
       "       162, 162, 154, 157, 158, 154,   0,   0,   0,   0, 154, 160, 156,\n",
       "       157, 154, 155, 159,   0, 155, 159, 162, 155, 162, 153, 119, 161,\n",
       "       154, 163, 153,   0, 150, 157,  41, 160, 154, 158, 160, 154, 154,\n",
       "       159, 163, 139, 160, 163,   0, 157,   0, 156, 153, 158,   0, 161,\n",
       "       157, 161, 161, 152, 157,   0, 162, 158, 139, 128, 160, 151, 139,\n",
       "       160, 158, 163, 161, 153, 157, 156, 149, 161,   0, 157,   5,   0,\n",
       "       156,   0, 155, 160, 137, 147, 145, 151, 158,   0, 155, 163, 162,\n",
       "       161, 153, 141, 161, 161, 157, 157, 161, 152, 161, 158, 154, 150,\n",
       "       161, 157,   0, 154,   0,   0, 155,   2, 155, 157, 160, 156, 157,\n",
       "       128,  80,  20, 156, 154, 160, 141, 101,   0,  47, 162, 154, 156,\n",
       "         0, 161, 163, 159,   0, 162, 158, 158, 151, 160,   0,   0, 154,\n",
       "       161, 160, 157,   0, 152,   0, 148, 160, 113,   0, 153, 156,   0,\n",
       "       154,  36,   0, 127, 163, 159, 160, 150, 157, 162,   0, 107, 160,\n",
       "       157, 161,   0, 161, 156, 162, 160, 164,   0, 158, 163,   0])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_associations = (ds_mat_b_freq != 0).sum(0) \n",
    "\n",
    "b_subset_indices = []\n",
    "b_subset_labels = []\n",
    "subset_size = 0\n",
    "\n",
    "for i in range(n_buildings):\n",
    "    if count_associations[i] > 0: #np.mean(count_associations):#[count_associations != 0]):\n",
    "        b_subset_indices.append(i)\n",
    "        b_subset_labels.append(index_name[i])\n",
    "        subset_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for scaling\n",
    "# track total frequency\n",
    "b_subset_N = 0\n",
    "\n",
    "# track building frequency\n",
    "b_subset_df = np.zeros((subset_size,))\n",
    "\n",
    "# track association frequency\n",
    "b_subset_tf = np.zeros((subset_size,subset_size))\n",
    "\n",
    "b_subset_tfidf = np.zeros((subset_size,subset_size))\n",
    "\n",
    "for i in range(subset_size):\n",
    "    for j in range(i+1,subset_size):\n",
    "        index1 = b_subset_indices[i]\n",
    "        index2 = b_subset_indices[j]\n",
    "        # update N\n",
    "        b_subset_N += ds_mat_b_freq[index1][index2]\n",
    "        \n",
    "        # update df\n",
    "        b_subset_df[i] += ds_mat_b_freq[index1][index2]\n",
    "        b_subset_df[j] += ds_mat_b_freq[index1][index2]\n",
    "        \n",
    "        # update tf\n",
    "        b_subset_tf[i][j] += ds_mat_b_freq[index1][index2]\n",
    "        b_subset_tf[j][i] += ds_mat_b_freq[index1][index2]\n",
    "\n",
    "# calculate tfidf\n",
    "# calculate tfidf\n",
    "for i in range(subset_size):\n",
    "    for j in range(i+1,subset_size):\n",
    "        if ((b_subset_df[i] + b_subset_df[j]) != 0) and (b_subset_tf[i][j] != 0):\n",
    "            tf = b_subset_tf[i][j]\n",
    "            bool_tf = max(0, b_subset_tf[i][j]/b_subset_tf[i][j])\n",
    "            log_tf = 1 + np.log(b_subset_tf[i][j])\n",
    "            aug_tf = 0.5 + 0.5*np.log(b_subset_tf[i][j])/b_subset_tf.max()\n",
    "            log_avg_tf = (1 + np.log(b_subset_tf[i][j]))/(1 + np.log(np.mean(b_subset_tf)))\n",
    "            idf = np.log(1 + (b_subset_N/(b_subset_df[i] + b_subset_df[j] - b_subset_tf[i][j])))\n",
    "            prob_idf = max(0, np.log((b_subset_N - b_subset_df[i] - b_subset_df[j] + b_subset_tf[i][j])/(b_subset_df[i] + b_subset_df[j] - b_subset_tf[i][j])))\n",
    "            b_subset_tfidf[i][j] = bool_tf * idf\n",
    "            #b_subset_tfidf[i][j] = b_subset_tf[i][j] * np.log(b_subset_N/(b_subset_df[i] + b_subset_df[j] - b_subset_tf[i][j]))\n",
    "\n",
    "# catch divide by zero problems\n",
    "b_subset_tfidf[b_subset_tfidf == inf] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mat_b_min_subset = np.zeros((subset_size,subset_size))\n",
    "ds_mat_b_avg_subset = np.zeros((subset_size,subset_size))\n",
    "\n",
    "for i in range(subset_size):\n",
    "    for j in range(i+1,subset_size):\n",
    "        index1 = b_subset_indices[i]\n",
    "        index2 = b_subset_indices[j]\n",
    "        ds_mat_b_min_subset[i][j] = ds_mat_b_min_subset[j][i] = b_subset_tfidf[i][j] * ds_mat_b_min[index1][index2]\n",
    "        ds_mat_b_avg_subset[i][j] = ds_mat_b_avg_subset[j][i] = b_subset_tfidf[i][j] * ds_mat_b_avg[index1][index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "np.savetxt('ds_mat_b_min_subset.csv', ds_mat_b_min_subset, delimiter=',', fmt='%d')\n",
    "np.savetxt('ds_mat_b_avg_subset.csv', ds_mat_b_avg_subset, delimiter=',', fmt='%d')\n",
    "\n",
    "# save subset labels\n",
    "np.savetxt(\"ds_mat_b_subset.csv\", b_subset_labels, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.64251207729468"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(count_associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.639593071058"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(count_associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.2994011976048"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(count_associations[count_associations != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ds_mat_b_min_scaled_subset == 0).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
       "         0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  4.,  0.,  2.,  0.,\n",
       "         1.,  0.,  1.,  0.,  1.,  1.,  1.,  4.,  3.,  3.,  7., 15.,  7.,\n",
       "         9., 18., 11.,  7., 16., 17., 11.,  9.]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164]),\n",
       " <BarContainer object of 164 artists>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(count_associations, bins=np.arange(count_associations.min(), count_associations.max()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18  1  1  3  2 11  1  2  2  5  4  1  1  1  1  3  2  1  2  1  1  3  1  4\n",
      "  3  1  3  1  1  3  1  2  1  2  1  3  4  4  1  5  1  1  1  2  1  1 13  1\n",
      "  1  1  1  7  2  1  2  1  1  2  1  1  2 13 28  1  3 13  1  2  1  1  2  1\n",
      "  2  5  1  2  2  1  1 15  6  8  3  1  2  1  1  1  1 15  1  1  1  1  1  5\n",
      "  1  2  2  4  2  2  1  2  3  2  1  2  1 24  1  2  1 14  1  2  2  1  1  2\n",
      "  1  1  1  2  1  1  1  1  1  4  9  1  3  6  2 25  1  1  1  3  2  1  1  3\n",
      "  1  1  2  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 68 207  46  49 207  50  53 106  64  45  50  47 207  57 101 207  54  97\n",
      " 122 207 207 207 207  48 207  48  45  45  53  50  49  53 207 207 207 207\n",
      "  53  47  51  50  53  52  48 207  52  48  45  52  45  54  88  46  53  44\n",
      "  54 207  57  50 166  47  53  49  47  53  53  48  44  68  47  44 207  50\n",
      " 207  51  54  49 207  46  50  46  46  55  50 207  45  49  68  79  47  56\n",
      "  68  47  49  44  46  54  50  51  58  46 207  50 202 207  51 207  52  47\n",
      "  70  60  62  56  49 207  52  44  45  46  54  66  46  46  50  50  46  55\n",
      "  46  49  53  57  46  50 207  53 207 207  52 205  52  50  47  51  50  79\n",
      " 127 187  51  53  47  66 106 207 160  45  53  51 207  46  44  48 207  45\n",
      "  49  49  56  47 207 207  53  46  47  50 207  55 207  59  47  94 207  54\n",
      "  51 207  53 171 207  80  44  48  47  57  50  45 207 100  47  50  46 207\n",
      "  46  51  45  47  43 207  49  44 207]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCESS POINTS\n",
    "# buildings DS matrices will be n_access_points x n_access_points\n",
    "# where n_access_points is the number of access points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mappings to make look ups when buidling Access Point ds matrices faster\n",
    "\n",
    "# map of installation_id (key) to index (between 0 and number of unique access points) (value)\n",
    "id_index = {}\n",
    "# map of index (key) to installation_id (value)\n",
    "index_id = {}\n",
    "\n",
    "# count of access points\n",
    "n_aps = 0\n",
    "\n",
    "for i, row in locations_df.iterrows():\n",
    "    id_index[row['installation_id']] = i\n",
    "    index_id[i] = [row['installation_id']]\n",
    "    n_aps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save buildings associated with each index for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track total frequency\n",
    "ap_N = 0\n",
    "\n",
    "# track building frequency\n",
    "ap_df = np.zeros((n_aps,))\n",
    "\n",
    "# track association frequency\n",
    "ap_tf = np.zeros((n_aps,n_aps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix AP_avg: \n",
    "# Pairwise distance of access points using average time apart and no scaling\n",
    "################################################################################\n",
    "ds_mat_ap_avg = np.zeros((n_aps,n_aps))\n",
    "\n",
    "# fill ds matrix\n",
    "for i, row in week_associations_times_df.iterrows():\n",
    "    if row['ap_1'] in id_name and row['ap_2'] in id_name: # handles any errors in the ids\n",
    "        index1 = id_index[row['ap_1']]\n",
    "        index2 = id_index[row['ap_2']]\n",
    "            \n",
    "        # update ds mat \n",
    "        if ds_mat_ap_avg[index1][index2] == 0:\n",
    "            ds_mat_ap_avg[index1][index2] += row['total_time'] / row['frequency']\n",
    "            ds_mat_ap_avg[index2][index1] += row['total_time'] / row['frequency']\n",
    "            \n",
    "            # update records for scaling\n",
    "            ap_N += row['frequency']\n",
    "            ap_df[index1] += row['frequency']\n",
    "            ap_df[index2] += row['frequency']\n",
    "            ap_tf[index1][index2] = row['frequency']\n",
    "            ap_tf[index2][index1] = row['frequency']\n",
    "        \n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_avg.csv', ds_mat_ap_avg, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix AP_min: \n",
    "# Pairwise distance of access points using min time apart and no scaling\n",
    "################################################################################\n",
    "ds_mat_ap_min = np.zeros((n_aps,n_aps))\n",
    "\n",
    "# fill ds matrix\n",
    "for i, row in week_associations_times_df.iterrows():\n",
    "    if row['ap_1'] in id_name and row['ap_2'] in id_name: # handles any errors in the ids\n",
    "        index1 = id_index[row['ap_1']]\n",
    "        index2 = id_index[row['ap_2']]\\\n",
    "            \n",
    "        if (ds_mat_ap_min[index1][index2] == 0) or (row['min_time'] < ds_mat_ap_min[index1][index2]):\n",
    "            ds_mat_ap_min[index1][index2] = row['min_time']\n",
    "            ds_mat_ap_min[index2][index1] = row['min_time']\n",
    "                \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_min.csv', ds_mat_ap_min, delimiter=',', fmt='%d')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# calculate how to scale the values\n",
    "####################################\n",
    "ap_tfidf = np.zeros((n_aps,n_aps))\n",
    "\n",
    "# calculate tfidf\n",
    "for i in range(n_aps):\n",
    "    for j in range(i+1,n_aps):\n",
    "        if (i != j) and (ds_mat_ap_avg[i][j] != 0) and ((ap_df[i] + ap_df[j] - ap_tf[i][j]) != 0):\n",
    "            ap_tfidf[i][j] = ap_tf[i][j] * np.log(ap_N/(ap_df[i] + ap_df[j] - ap_tf[i][j]))\n",
    "\n",
    "# catch divide by zero problems\n",
    "ap_tfidf[ap_tfidf == inf] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix AP_avg_scaled: \n",
    "# Pairwise distance of access points using average time apart with frequency scaling\n",
    "################################################################################\n",
    "ds_mat_ap_avg_scaled = np.zeros((n_aps,n_aps))\n",
    "\n",
    "for i in range(n_aps):\n",
    "    for j in range(i+1,n_aps):\n",
    "        if (i != j):\n",
    "            ds_mat_ap_avg_scaled[i][j] = ds_mat_ap_avg_scaled[j][i] = ap_tfidf[i][j] * ds_mat_ap_avg[i][j]\n",
    "            \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_avg_scaled.csv', ds_mat_ap_avg_scaled, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Build Dissimilarity Matrix AP_min_scaled: \n",
    "# Pairwise distance of access points using min time apart with frequency scaling\n",
    "################################################################################\n",
    "ds_mat_ap_min_scaled = np.zeros((n_aps,n_aps))\n",
    "\n",
    "for i in range(n_aps):\n",
    "    for j in range(i+1,n_aps):\n",
    "        if (i != j):\n",
    "            ds_mat_ap_min_scaled[i][j] = ds_mat_ap_min_scaled[j][i] = ap_tfidf[i][j] * ds_mat_ap_min[i][j]\n",
    "            \n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_min_scaled.csv', ds_mat_ap_min_scaled, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.        ,      0.        ,  50607.38694466, ...,\n",
       "         34896.35736843,  19451.99216959,  73287.04973147],\n",
       "       [     0.        ,      0.        ,    916.56644149, ...,\n",
       "         31080.13425742,  29970.39746394,  39135.37016008],\n",
       "       [ 50607.38694466,    916.56644149,      0.        , ...,\n",
       "        110455.06309047,  79606.528541  ,  16389.52629018],\n",
       "       ...,\n",
       "       [ 34896.35736843,  31080.13425742, 110455.06309047, ...,\n",
       "             0.        ,   1007.38015348,   1889.03022077],\n",
       "       [ 19451.99216959,  29970.39746394,  79606.528541  , ...,\n",
       "          1007.38015348,      0.        ,    564.82401915],\n",
       "       [ 73287.04973147,  39135.37016008,  16389.52629018, ...,\n",
       "          1889.03022077,    564.82401915,      0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get subset of access points with enough data\n",
    "num_associations = (ap_tf != 0).sum(0)     \n",
    "\n",
    "ds_mat_ap_subset_indices = []\n",
    "ds_mat_ap_subset_ids = []\n",
    "ds_mat_ap_subset_labels = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(n_aps):\n",
    "    if num_associations[i] >= (np.mean(num_associations)):\n",
    "        count += 1\n",
    "        ds_mat_ap_subset_indices.append(i)\n",
    "        ds_mat_ap_subset_ids.append(index_id[i])\n",
    "        ds_mat_ap_subset_labels.append(id_name[index_id[i][0]])\n",
    "\n",
    "ds_mat_ap_min_scaled_subset = np.zeros((count,count))\n",
    "        \n",
    "for i in range(count):\n",
    "    for j in range(i+1, count):\n",
    "        index1 = ds_mat_ap_subset_indices[i]\n",
    "        index2 = ds_mat_ap_subset_indices[j]\n",
    "        ds_mat_ap_min_scaled_subset[i][j] = ds_mat_ap_min_scaled_subset[j][i] = ds_mat_ap_min_scaled[index1][index2]\n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_min_scaled_subset.csv', ds_mat_ap_min_scaled_subset, delimiter=',', fmt='%d')\n",
    "\n",
    "# save subset labels\n",
    "np.savetxt(\"ds_mat_ap_subset_labels.csv\", ds_mat_ap_subset_labels, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0. 246. ...   0.   0.   0.]\n",
      "0.0\n",
      "8328.0\n"
     ]
    }
   ],
   "source": [
    "num_outside_associations = np.zeros((n_aps))\n",
    "for i in range(n_aps):\n",
    "    curr_name = id_name[index_id[i][0]]\n",
    "    for j in range(n_aps):\n",
    "        check_name = id_name[index_id[j][0]]\n",
    "        if (curr_name != check_name) and (ap_tf[i][j] != 0):\n",
    "            num_outside_associations[i] += 1\n",
    "print(num_outside_associations)\n",
    "print(min(num_outside_associations))\n",
    "print(max(num_outside_associations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105.9190688369556\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(num_outside_associations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset of access points with enough data   \n",
    "\n",
    "ds_mat_ap_subset2_indices = []\n",
    "ds_mat_ap_subset2_ids = []\n",
    "ds_mat_ap_subset2_labels = []\n",
    "\n",
    "count2 = 0\n",
    "\n",
    "for i in range(n_aps):\n",
    "    if num_outside_associations[i] >= (np.mean(num_outside_associations) + np.std(num_outside_associations)):\n",
    "        count2 += 1\n",
    "        ds_mat_ap_subset2_indices.append(i)\n",
    "        ds_mat_ap_subset2_ids.append(index_id[i])\n",
    "        ds_mat_ap_subset2_labels.append(id_name[index_id[i][0]])\n",
    "\n",
    "ds_mat_ap_min_scaled_subset2 = np.zeros((count,count))\n",
    "        \n",
    "for i in range(count2):\n",
    "    for j in range(i+1, count2):\n",
    "        index1 = ds_mat_ap_subset2_indices[i]\n",
    "        index2 = ds_mat_ap_subset2_indices[j]\n",
    "        ds_mat_ap_min_scaled_subset2[i][j] = ds_mat_ap_min_scaled_subset2[j][i] = ds_mat_ap_min_scaled[index1][index2]\n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_min_scaled_subset2.csv', ds_mat_ap_min_scaled_subset2, delimiter=',', fmt='%d')\n",
    "\n",
    "# save subset labels\n",
    "np.savetxt(\"ds_mat_ap_subset2_labels.csv\", ds_mat_ap_subset2_labels, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset using min for ones in same building and average for diff buildings\n",
    "# get subset of access points with enough data   \n",
    "\n",
    "ds_mat_ap_subset3 = np.zeros((count,count))\n",
    "        \n",
    "for i in range(count2):\n",
    "    for j in range(i+1, count2):\n",
    "        index1 = ds_mat_ap_subset2_indices[i]\n",
    "        index2 = ds_mat_ap_subset2_indices[j]\n",
    "        name1 = ds_mat_ap_subset2_labels[i]\n",
    "        name2 = ds_mat_ap_subset2_labels[j]\n",
    "        if name1 == name2:\n",
    "            ds_mat_ap_subset3[i][j] = ds_mat_ap_subset3[j][i] = ds_mat_ap_min[index1][index2]\n",
    "        else:\n",
    "            ds_mat_ap_subset3[i][j] = ds_mat_ap_subset3[j][i] = ds_mat_ap_avg[index1][index2]\n",
    "        \n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_subset3.csv', ds_mat_ap_subset3, delimiter=',', fmt='%d')\n",
    "\n",
    "# save subset labels\n",
    "np.savetxt(\"ds_mat_ap_subset3_labels.csv\", ds_mat_ap_subset2_labels, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset using min for ones in same building and average for diff buildings\n",
    "# get subset of access points with enough data   \n",
    "\n",
    "ds_mat_ap_subset4 = np.zeros((count,count))\n",
    "        \n",
    "for i in range(count2):\n",
    "    for j in range(i+1, count2):\n",
    "        index1 = ds_mat_ap_subset2_indices[i]\n",
    "        index2 = ds_mat_ap_subset2_indices[j]\n",
    "        name1 = ds_mat_ap_subset2_labels[i]\n",
    "        name2 = ds_mat_ap_subset2_labels[j]\n",
    "        if name1 == name2:\n",
    "            ds_mat_ap_subset4[i][j] = ds_mat_ap_subset4[j][i] = (ap_tf[index1][index2]/n_aps) *ds_mat_ap_min[index1][index2]\n",
    "        else:\n",
    "            ds_mat_ap_subset4[i][j] = ds_mat_ap_subset4[j][i] = ds_mat_ap_avg[index1][index2]\n",
    "        \n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_subset4.csv', ds_mat_ap_subset4, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset using min for ones in same building and average for diff buildings\n",
    "# get subset of access points with enough data   \n",
    "\n",
    "ds_mat_ap_subset5 = np.zeros((count,count))\n",
    "        \n",
    "for i in range(count2):\n",
    "    for j in range(i+1, count2):\n",
    "        index1 = ds_mat_ap_subset2_indices[i]\n",
    "        index2 = ds_mat_ap_subset2_indices[j]\n",
    "        name1 = ds_mat_ap_subset2_labels[i]\n",
    "        name2 = ds_mat_ap_subset2_labels[j]\n",
    "        if name1 == name2:\n",
    "            ds_mat_ap_subset5[i][j] = ds_mat_ap_subset5[j][i] = (ap_tf[index1][index2]/n_aps) * ds_mat_ap_min[index1][index2]\n",
    "        else:\n",
    "            ds_mat_ap_subset5[i][j] = ds_mat_ap_subset5[j][i] = ((ap_df[index1] + ap_df[index2])/n_aps) * ds_mat_ap_avg[index1][index2]\n",
    "        \n",
    "\n",
    "# export to csv\n",
    "np.savetxt('ds_mat_ap_subset4.csv', ds_mat_ap_subset4, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21186052540.404846\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-99fbcc7dd402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_mat_ap_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_mat_ap_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "print(sum(sum(ds_mat_ap_min)))\n",
    "print(max(ds_mat_ap_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# save labels for ds mat ap\n",
    "####################################\n",
    "ap_names = []\n",
    "for i in range(n_aps):\n",
    "    ap_names.append(id_name[index_id[i][0]])\n",
    "   \n",
    "\n",
    "np.savetxt(\"ds_mat_labels_ap.csv\", ap_names, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
